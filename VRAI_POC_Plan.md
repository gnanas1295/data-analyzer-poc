# VRAI - POC Plan

- Project Overview & Technical Stack
    - **Project Name:** "Mini-HEAT" Simulation Data Analyzer
    - **Objective:** To create a cloud-native web service that ingests simulation data, performs analysis using Pandas, persists the results in a NoSQL database, and is deployed automatically via a CI/CD pipeline.
    - **Core Functionality:** Provides an API endpoint to analyze a trainee's performance from a simulation log and returns a score and summary.
    
- Technical Stack
    - **Backend Language:** Python 3.10+
    - **API Framework:** FastAPI
    - **Data Analysis:** Pandas
    - **Data Validation:** Pydantic
    - **Dependency Management:** Poetry
    - **Source Control:** Git / GitHub
    - **Cloud Provider:** Microsoft Azure
    - **Hosting:** Azure App Service (Linux)
    - **Database:** Azure Cosmos DB (NoSQL API)
    - **CI/CD:** GitHub Actions
- System Architecture & Data Flow
    
    ```mermaid
    graph TD
        subgraph "Developer"
            A[Code Push to GitHub Main Branch]
        end
    
        subgraph "GitHub Actions CI/CD"
            B{Trigger Pipeline}
            C[Build & Test]
            D[Deploy to Azure]
        end
    
        subgraph "Microsoft Azure"
            E[Azure App Service]
            F[Python/FastAPI Application]
            G[Azure Cosmos DB]
        end
    
        subgraph "End User / Simulation Software"
            H[API Client]
        end
    
        A --> B --> C --> D --> E
        E -- hosts --> F
        H -- HTTP POST Request --> F
        F -- Reads/Writes Data --> G
        F -- HTTP Response --> H
    
        style G fill:#9f9,stroke:#333,stroke-width:2px
        style E fill:#9cf,stroke:#333,stroke-width:2px
    ```
    
- API Design Details
    
    The Plan as of now is to create two endpoints
    
    - Endpoint 1: `POST /analyze`
        - **Purpose:** The core endpoint that receives data, performs analysis, and stores the result.
        - **HTTP Method:** `POST`
        - **URL:** `/analyze`
        - **Request Body (`application/json`):**
            - **`trainee_id`** (string): A unique identifier for the trainee.
            - **`simulation_log`** (array of objects): A time-series log of the simulation.
                - **`timestamp`** (float): Time in seconds from the start.
                - **`altitude`** (integer): The trainee's altitude at that timestamp.
                - **`speed`** (integer): The trainee's speed at that timestamp.
                - **`event`** (string): A notable event that occurred (e.g., "turbulence", "correction").
        - **Success Response (200 OK):**
            - Returns the full document that was saved to Cosmos DB, including a unique `id` generated by the database.
        - **Error Responses:**
            - **422 Unprocessable Entity:** If the request body does not match the required format.
            - **500 Internal Server Error:** If there's an issue with the analysis or database connection
    - GET /
        - **Purpose:** A simple health check to confirm the service is online and running.
        - **HTTP Method:** `GET`
        - **URL:** `/`
        - **Success Response (200 OK):**
            
            {
            "status": "ok",
            "service": "VRAI Simulation Data Analyzer"
            }
            
- Data Persistence Design (Azure Cosmos DB)
    - **Service:** Azure Cosmos DB for NoSQL.
    - **Database Name:** `SimulationDb`
    - **Container Name:** `AnalysisResults`
    - **Partition Key:** `/trainee_id`. This is crucial for efficiently querying data for a specific trainee as the dataset grows.
    - **Stored Document Schema:** For each successful analysis, a single JSON document will be saved. The document will contain the original input data plus the calculated analysis results for a complete record.
    
    ```python
    {
        "id": "auto-generated-guid",
        "trainee_id": "pilot-07",
        "simulation_timestamp_utc": "2025-08-22T18:30:00Z",
        "input_data": {
            "simulation_log": [
                {"timestamp": 0.0, "altitude": 5000, "speed": 250, "event": "start"},
                {"timestamp": 2.5, "altitude": 4500, "speed": 280, "event": "turbulence"}
            ]
        },
        "analysis_summary": {
            "performance_score": 80,
            "total_duration_seconds": 2.5,
            "average_speed": 265.0,
            "critical_events": {
                "overspeed_incidents": 1,
                "unstable_approach_events": 0
            }
        }
    }
    ```
    
- Flow Charts (Mermaid Format)
    - Application Logic Flow (`POST /analyze`)
        
        ```mermaid
        sequenceDiagram
            participant Client
            participant FastAPI App
            participant Pandas
            participant Cosmos DB
        
            Client->>FastAPI App: POST /analyze with JSON body
            activate FastAPI App
            FastAPI App->>FastAPI App: Validate data with Pydantic
            alt Data is Invalid
                FastAPI App-->>Client: 422 Unprocessable Entity
            else Data is Valid
                FastAPI App->>Pandas: Load simulation_log into DataFrame
                activate Pandas
                Pandas->>Pandas: Perform calculations (avg speed, count events)
                Pandas-->>FastAPI App: Return analysis results
                deactivate Pandas
                FastAPI App->>FastAPI App: Assemble final JSON document (input + results)
                FastAPI App->>Cosmos DB: Save document to 'AnalysisResults' container
                activate Cosmos DB
                Cosmos DB-->>FastAPI App: Confirm save and return new document with 'id'
                deactivate Cosmos DB
                FastAPI App-->>Client: 200 OK with saved document
            end
            deactivate FastAPI App
        ```
        
    - CI/CD DevOps Pipeline Flow (GitHub Actions)
        
        ```mermaid
        graph TD
            A(Developer pushes commit to 'main' branch) --> B{Pipeline Triggered};
            B --> C[Step 1: Checkout Code];
            C --> D[Step 2: Setup Python & Poetry];
            D --> E[Step 3: Install Dependencies];
            E --> F[Step 4: Lint & Run Tests];
            F --> G{Tests Pass?};
            G -- No --> H[Fail Pipeline & Notify];
            G -- Yes --> I[Step 5: Log in to Azure];
            I --> J[Step 6: Deploy to Azure App Service];
            J --> K{Deployment Succeeded?};
            K -- No --> H;
            K -- Yes --> L[Success & Purge CDN Cache];
        
            style H fill:#f99,stroke:#333,stroke-width:2px
            style L fill:#9f9,stroke:#333,stroke-width:2px
        ```